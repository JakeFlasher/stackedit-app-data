
## Constable: Improving Performance and Power Efficiency by Safely Eliminating Load Instruction Execution
### Background & Key insights

#### Load instructions are a key limiter of instruction-level parallelism (ILP), Safely breaking load data dependency without executing a load instruction may provide additional performance benefits.


![输入图片说明](https://raw.githubusercontent.com/JakeFlasher/stackedit-app-data/master/imgs/2024-07-31/prior_tech.png)

> - ***A dynamic load instance I2 of a static load instruction I is bound to fetch the same value from the same memory location as the previous dynamic instance I1 of the same static load instruction when the following two conditions are satisfied.*** 
	> 	-  Condition 1: None of the source registers of I has been written between the occurrences of I1 and I2. 
	> 	-  Condition 2: No store or store request has arrived to the memory address of I1 between the occurrences of I1 and I2. 

> Satisfying Condition 1 ensures that I2 would have the same load address as I1, and thus the address computation operation of I2 can be safely eliminated. Satisfying Condition 2 ensures that I2 would fetch the same value from the memory as I1, and thus the data fetch operation of I2 can be safely eliminated.
### Analysis of Global-Stable Loads
>- ***Some loads repeatedly fetch the same data value from same load address across entire workload***
Both operations, address generation & data fetch, produce identical results across all dynamic instances
Prime targets for breaking data dependency without execution

> - ***Why do these loads even exist in well-optimized real-world workloads?***
Accessing global-scope variables
Accessing local variables of inline functions
Limited set of architectural registers

>- ***Can increasing architectural registers help?***
Very small change even after doubling x64 registers
![输入图片说明](https://raw.githubusercontent.com/JakeFlasher/stackedit-app-data/master/imgs/2024-07-31/register.png)
>- ***Deeper characterization of global-stable loads***
Which addressing mode do they use?
How far away do they appear in a workload?
![](https://raw.githubusercontent.com/JakeFlasher/stackedit-app-data/master/imgs/2024-07-31/fraction_plus.png)

### Characterization of Global-Stable Loads 

### Do they limit ILP even when using load value prediction and memory renaming? 

> ####  In an aggressive OoO processor with 6-wide issue, 3 load ports, a load value predictor (EVES [Seznec, CVP’18]), and memory renaming enabled, global-stable loads limit ILP due to resource dependence. What’s the performance headroom of mitigating the resource dependence?


### Key Improvements over Literature
#### ***A purely-microarchitectural technique, aiming to mitigates both load data dependence and load resource dependence, by safely eliminating the entire execution of a load instruction***



 > - **Focus only on loads that are likely stable**
> - **Eliminate loads early in the pipeline**
	> 	 - Integration of Constable into the processor pipeline
	> 	- Ensuring safe and correct elimination in presence of
	> 		- Out-of-order load issue
	> 		- Multi-threaded & multi-core execution
	> 		- Wrong-path execution

> - **Ensure correctness in today’s processors**
	> 	- Maintain correctness in presence of out-of-order load issue
		>	- Maintain coherence in multi-threaded & multi-core execution
		
![输入图片说明](https://raw.githubusercontent.com/JakeFlasher/stackedit-app-data/master/imgs/2024-07-31/headroom.png)

![输入图片说明](https://raw.githubusercontent.com/JakeFlasher/stackedit-app-data/master/imgs/2024-07-31/resources_lag.png)

### Experimental Setups

> Industry-grade x86-64 simulator modeling aggressive OoO processor
	> 	- 8-wide fetch, 6-wide issue to 3 load ports, 512-entry ROB
	> - With memory renaming, zero/constant/move elimination, branch folding
	> - Five prefetchers throughout cache hierarchy

> Mechanisms compared against
> - EVES, the state-of-the-art load value predictor [Seznec, CVP’18]
> - Early Load Address Resolution [Bekerman+, ISCA’00]
> - Register File Prefetching [Shukla+, ISCA’22]


> Configuration
	> - No simultaneous multi-threading (SMT)
 > -	2-way SMT


>90 workloads of wide variety
> - All from SPEC CPU 2017
> - Client (SYSMark, DaCapo, ...)
> - Enterprise (SPECjbb, SPECjEnterprise, ...)
> - Server (BigBench, Hadoop, ...)

![输入图片说明](https://raw.githubusercontent.com/JakeFlasher/stackedit-app-data/master/imgs/2024-07-31/workloads.jpg)

![输入图片说明](https://raw.githubusercontent.com/JakeFlasher/stackedit-app-data/master/imgs/2024-07-31/simulation_design.jpg) 

### Results
![输入图片说明](https://raw.githubusercontent.com/JakeFlasher/stackedit-app-data/master/imgs/2024-07-31/speedup.png)


## Micro-architectural Design
![输入图片说明](https://raw.githubusercontent.com/JakeFlasher/stackedit-app-data/master/imgs/2024-07-31/design.jpg)
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTYxNzc1NjkwNCwxNzc2NTY5NDUsLTIyMz
czNDU3MywtNDYyNjM2MjI0LDEzODMzNTcwMzUsMTY1NDE0NzA2
Myw1OTkyNTAxMjksLTg1MTIwMTY1MiwtMjA1Mjg5NDQwOCwyMD
MyMjU2NzQzXX0=
-->